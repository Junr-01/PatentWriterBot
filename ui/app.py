import streamlit as st
import sys
import os
from pathlib import Path
from dotenv import load_dotenv
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agent.agent import run_patentbot_async_stream, init_patentbot
from agent.agent import shoud_stop

def _get_status_icon(status: str) -> str:
    """æ ¹æ®çŠ¶æ€è¿”å›å¯¹åº”çš„å›¾æ ‡"""
    status_map = {
        "pending": "â³",
        "in_progress": "ğŸ”„",
        "completed": "âœ…",
        "cancelled": "âŒ",
    }
    return status_map.get(status.lower(), "ğŸ“‹")

def _get_status_color(status: str) -> str:
    """æ ¹æ®çŠ¶æ€è¿”å›å¯¹åº”çš„é¢œè‰²"""
    status_map = {
        "pending": "gray",
        "in_progress": "blue",
        "completed": "green",
        "cancelled": "red",
    }
    return status_map.get(status.lower(), "gray")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸“åˆ©å†™ä½œBot",
    page_icon="ğŸ“",
    layout="centered",
    initial_sidebar_state="expanded"
)

# æ ‡é¢˜
st.title("ğŸ“ ä¸“åˆ©å†™ä½œæœºå™¨äºº")

# åˆå§‹åŒ– session state
if 'uploaded_file_name' not in st.session_state:
    st.session_state.uploaded_file_name = None
if 'generation_status' not in st.session_state:
    st.session_state.generation_status = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'is_generating' not in st.session_state:
    st.session_state.is_generating = False

# ç»„ä»¶1ï¼šæ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
st.header("æ¨¡å‹é€‰æ‹©")
model_options = ['deepseek-chat', 'gpt-5', 'gpt-5-mini']
selected_model = st.selectbox(
    "è¯·é€‰æ‹©æ¨¡å‹",
    options=model_options,
    index=0,  # é»˜è®¤é€‰æ‹© 'deepseek-chat'
    help="é€‰æ‹©ç”¨äºç”Ÿæˆä¸“åˆ©çš„ AI æ¨¡å‹"
)

# API Key è¾“å…¥ï¼ˆæ ¹æ®æ¨¡å‹é€‰æ‹©æ˜¾ç¤ºä¸åŒçš„è¾“å…¥æ¡†ï¼‰
st.header("API é…ç½®")

# æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºç›¸åº”çš„ API key è¾“å…¥æ¡†
if selected_model == 'deepseek-chat':
    api_key_label = "DeepSeek API Key"
    api_key_help = "è¯·è¾“å…¥æ‚¨çš„ DeepSeek API Keyã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·è®¿é—® https://platform.deepseek.com/ è·å–ã€‚"
    env_key_name = "DEEPSEEK_API_KEY"
elif selected_model in ['gpt-5', 'gpt-5-mini']:
    api_key_label = "OpenAI API Key"
    api_key_help = "è¯·è¾“å…¥æ‚¨çš„ OpenAI API Keyã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·è®¿é—® https://platform.openai.com/ è·å–ã€‚"
    env_key_name = "OPENAI_API_KEY"
else:
    api_key_label = "API Key"
    api_key_help = "è¯·è¾“å…¥ API Key"
    env_key_name = "API_KEY"

# ä»ç¯å¢ƒå˜é‡è¯»å–é»˜è®¤å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
default_api_key = os.getenv(env_key_name, "")

# API Key è¾“å…¥æ¡†
api_key = st.text_input(
    api_key_label,
    value=st.session_state.get(f'api_key_{selected_model}', default_api_key),
    type="password",
    help=api_key_help,
    placeholder="è¯·è¾“å…¥API Keyï¼ŒæŒ‰å›è½¦è¾“å…¥ï¼ï¼ï¼"
)

if st.session_state.is_generating:
    shoud_stop()
    st.session_state.is_generating = False

# ä¿å­˜åˆ° session state
st.session_state[f'api_key_{selected_model}'] = api_key

# æ˜¾ç¤º API Key çŠ¶æ€
if api_key:
    # è®¾ç½®ç¯å¢ƒå˜é‡
    if api_key != default_api_key:
        os.environ[env_key_name] = api_key
    #åˆå§‹åŒ–æ¨¡å‹åŠä»£ç†
    init_patentbot(model_name=selected_model)

    st.success(f"âœ… {api_key_label} å·²é…ç½®")
    # æ˜¾ç¤ºéƒ¨åˆ† API Keyï¼ˆå‰4ä½å’Œå4ä½ï¼‰
    masked_key = api_key[:4] + "..." + api_key[-4:] if len(api_key) > 8 else "****"
    st.caption(f"å½“å‰é…ç½®: {masked_key}")
else:
    st.warning(f"âš ï¸ è¯·é…ç½® {api_key_label}")

# ç»„ä»¶2ï¼šæ–‡ä»¶ä¸Šä¼ 
st.header("æ–‡ä»¶ä¸Šä¼ ")
uploaded_file = st.file_uploader(
    "é€‰æ‹©æŠ€æœ¯äº¤åº•ä¹¦æ–‡ä»¶",
    type=['docx', 'doc', 'txt', 'md'],
    help="ä¸Šä¼ æŠ€æœ¯äº¤åº•ä¹¦æ–‡ä»¶ï¼Œæ”¯æŒword, pdfç­‰"
)

if uploaded_file is None:
    st.session_state.uploaded_file_name = None
    if st.session_state.is_generating:
        shoud_stop()
        st.session_state.is_generating = False
else:
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    upload_dir = project_root / "workspace" / "data"
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ–‡ä»¶
    file_path = upload_dir / uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # å¦‚æœä¸Šä¼ äº†æ–°æ–‡ä»¶ï¼Œæ¸…é™¤ä¹‹å‰çš„ç”ŸæˆçŠ¶æ€
    if st.session_state.uploaded_file_name != uploaded_file.name:
        st.session_state.generation_status = None
        if st.session_state.is_generating:
            shoud_stop()
            st.session_state.is_generating = False
    
    st.session_state.uploaded_file_name = uploaded_file.name
    st.success(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ : {uploaded_file.name}")
    
    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    st.info(f"ğŸ“„ æ–‡ä»¶å: {uploaded_file.name}\nğŸ“Š æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

# ç»„ä»¶3ï¼šç”Ÿæˆä¸“åˆ©æŒ‰é’®
st.header("ç”Ÿæˆä¸“åˆ©")
if st.session_state.uploaded_file_name:
    # æ£€æŸ¥ API Key æ˜¯å¦å·²é…ç½®
    if not st.session_state[f'api_key_{selected_model}']:
        st.error(f"âŒ è¯·å…ˆé…ç½®api key!!!")
    else:
        # æŒ‰é’®åŒºåŸŸ
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button(
                "ğŸš€ å¼€å§‹ç”Ÿæˆä¸“åˆ©",
                type="primary",
                use_container_width=True,
                disabled=st.session_state.get('is_generating', False)
            ):
                st.session_state.generation_status = None
                st.session_state.is_generating = True
                

        with col2:
            if st.button(
                "â¹ï¸ åœæ­¢ç”Ÿæˆä¸“åˆ©",
                type="secondary",
                use_container_width=True,
                disabled=not st.session_state.get('is_generating', False)
            ):
                #è®©åç«¯çº¿ç¨‹ç»“æŸè¿è¡Œ
                shoud_stop()
                st.session_state.generation_status = None
                st.session_state.is_generating = False
                
        
        # å¦‚æœæ­£åœ¨ç”Ÿæˆï¼Œæ‰§è¡Œç”Ÿæˆé€»è¾‘
        if st.session_state.is_generating:
            # åˆ›å»ºç”¨äºæ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨çš„å®¹å™¨
            progress_container = st.container()
            result_container = st.empty()
            error_container = st.empty()
            
            try:
                with progress_container:
                    st.subheader("ğŸ“‹ ä»»åŠ¡è¿›å±•")
                    todo_placeholder = st.empty()
                    messages = []
                    current_todos = {}
                    
                    for chunk in run_patentbot_async_stream(st.session_state.uploaded_file_name):
                        todo_list = []
                        for step, data in chunk.items():
                            if step == "tools" and data.get("todos"):
                                todo_list = [(item["content"], item["status"]) for item in data.get("todos")]
                            if step == "model" and data.get("messages"):
                                messages += data.get("messages")
                        
                        # æ›´æ–°ä»»åŠ¡åˆ—è¡¨ï¼ˆä½¿ç”¨æœ€æ–°çš„ todo_list è¦†ç›–ï¼‰
                        if todo_list:
                            current_todos.clear()
                            for content, status in todo_list:
                                current_todos[content] = status
                        
                        # å®æ—¶æ›´æ–°æ˜¾ç¤ºå½“å‰ä»»åŠ¡åˆ—è¡¨
                        with todo_placeholder.container():
                            # è®¡ç®—è¿›åº¦
                            total = len(current_todos)
                            completed = sum(1 for s in current_todos.values() if s.lower() == "completed")
                            in_progress = sum(1 for s in current_todos.values() if s.lower() == "in_progress")
                            pending = sum(1 for s in current_todos.values() if s.lower() == "pending")
                            
                            # æ˜¾ç¤ºè¿›åº¦æ¡
                            progress = completed / total if total > 0 else 0
                            st.progress(progress, text=f"è¿›åº¦: {completed}/{total} å·²å®Œæˆ | {in_progress} è¿›è¡Œä¸­ | {pending} å¾…å¤„ç†")
                            
                            # æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨ï¼ˆæŒ‰ç…§åŸå§‹é¡ºåºæ˜¾ç¤ºï¼‰
                            st.markdown("#### ä»»åŠ¡åˆ—è¡¨")
                            for content, status in todo_list:
                                icon = _get_status_icon(status)
                                color = _get_status_color(status)
                                status_text = {
                                    "pending": "å¾…å¤„ç†",
                                    "in_progress": "è¿›è¡Œä¸­",
                                    "completed": "å·²å®Œæˆ",
                                    "cancelled": "å·²å–æ¶ˆ",
                                }.get(status.lower(), status)
                                
                                # ä½¿ç”¨æ›´æ¸…æ™°çš„æ˜¾ç¤ºæ–¹å¼
                                if status.lower() == "in_progress":
                                    st.markdown(f"{icon} **{content}** - <span style='color: {color}; font-weight: bold'>{status_text}</span>", 
                                                unsafe_allow_html=True)
                                else:
                                    st.markdown(f"{icon} {content} - <span style='color: {color}'>{status_text}</span>", 
                                                unsafe_allow_html=True)
                # ç”Ÿæˆå®Œæˆåæ˜¾ç¤ºç»“æœ
                # æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡æ˜¯å¦å…¨éƒ¨å®Œæˆ
                all_completed = True
                if current_todos:
                    for status in current_todos.values():
                        if status.lower() != "completed":
                            all_completed = False
                            break
                else:
                    all_completed = False
                
                # æ ¹æ®ä»»åŠ¡å®Œæˆæƒ…å†µæ˜¾ç¤ºç›¸åº”æ¶ˆæ¯å’Œç»“æœ
                with result_container.container():
                    if all_completed:
                        st.session_state.generation_status = "success"
                        st.success("âœ… ä¸“åˆ©ç”Ÿæˆå®Œæˆï¼")
                    else:
                        st.session_state.generation_status = "error"
                        st.error("âŒ ä¸“åˆ©ç”Ÿæˆå¤±è´¥ï¼")
                    
                    # æ˜¾ç¤ºæœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
                    if messages:
                        st.markdown("---")
                        st.markdown("### ğŸ“„ ç”Ÿæˆç»“æœ")
                        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
                        last_message = messages[-1]
                        content = last_message.content
                        # æ˜¾ç¤ºå†…å®¹
                        st.markdown(content)
                # é‡ç½®ç”ŸæˆçŠ¶æ€
                st.session_state.is_generating = False
                            
            except Exception as e:
                st.session_state.generation_status = "error"
                st.session_state.is_generating = False
                result_container.error(f"âŒ ç”Ÿæˆä¸“åˆ©æ—¶å‡ºé”™: {str(e)}")
                with error_container:
                    st.exception(e)
else:
    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æŠ€æœ¯äº¤åº•ä¹¦æ–‡ä»¶")

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.header("ğŸ“‹ ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. **é€‰æ‹©æ¨¡å‹**: ä»ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è¦ä½¿ç”¨çš„ AI æ¨¡å‹
    2. **é…ç½® API Key**: æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è¾“å…¥ç›¸åº”çš„ API Key
    3. **ä¸Šä¼ æ–‡ä»¶**: ä¸Šä¼ æŠ€æœ¯äº¤åº•ä¹¦æ–‡ä»¶ï¼ˆæ”¯æŒword, pdfç­‰ï¼‰
    4. **ç”Ÿæˆä¸“åˆ©**: ç‚¹å‡»"å¼€å§‹ç”Ÿæˆä¸“åˆ©"æŒ‰é’®å¼€å§‹å¤„ç†
    
    ### æ”¯æŒçš„æ¨¡å‹
    - **deepseek-chat**ï¼ˆé»˜è®¤ï¼‰
    - **gpt-5**ã€**gpt-5-mini**
    """)

